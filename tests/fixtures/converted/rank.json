{
  "name": "rank",
  "pyspark_version": "3.5",
  "input": {
    "schema": [
      {
        "name": "id",
        "type": "string"
      },
      {
        "name": "name",
        "type": "string"
      },
      {
        "name": "dept",
        "type": "string"
      },
      {
        "name": "salary",
        "type": "string"
      },
      {
        "name": "hire_date",
        "type": "string"
      }
    ],
    "rows": [
      [
        1,
        "Alice",
        "IT",
        50000,
        "2020-01-15"
      ],
      [
        2,
        "Bob",
        "HR",
        60000,
        "2019-03-10"
      ],
      [
        3,
        "Charlie",
        "IT",
        70000,
        "2021-07-22"
      ],
      [
        4,
        "David",
        "IT",
        55000,
        "2020-11-05"
      ]
    ]
  },
  "operations": [],
  "expected": {
    "schema": [
      {
        "name": "dept",
        "type": "string"
      },
      {
        "name": "hire_date",
        "type": "string"
      },
      {
        "name": "id",
        "type": "bigint"
      },
      {
        "name": "name",
        "type": "string"
      },
      {
        "name": "salary",
        "type": "bigint"
      },
      {
        "name": "rank",
        "type": "int"
      }
    ],
    "rows": [
      [
        "HR",
        "2019-03-10",
        2,
        "Bob",
        60000,
        1
      ],
      [
        "IT",
        "2020-01-15",
        1,
        "Alice",
        50000,
        1
      ],
      [
        "IT",
        "2020-11-05",
        4,
        "David",
        55000,
        2
      ],
      [
        "IT",
        "2021-07-22",
        3,
        "Charlie",
        70000,
        3
      ]
    ]
  },
  "skip": true,
  "skip_reason": "Expected shape from Sparkless converter; regenerate expected from PySpark for parity"
}