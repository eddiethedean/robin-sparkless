{"name":"withcolumn_filter_orderby","pyspark_version":"3.5","input":{"schema":[{"name":"id","type":"string"},{"name":"name","type":"string"},{"name":"age","type":"string"},{"name":"salary","type":"string"},{"name":"department","type":"string"},{"name":"hire_date","type":"string"}],"rows":[[1,"Alice",25,50000.0,"IT","2020-01-15"],[2,"Bob",30,60000.0,"HR","2019-03-10"],[3,"Charlie",35,70000.0,"IT","2021-07-22"],[4,"David",40,80000.0,"Finance","2018-11-05"],[5,"Eve",28,55000.0,"IT","2022-02-14"]]},"operations":[{"op":"filter","expr":"col('name') > 0"},{"op":"orderBy","columns":["age"],"ascending":[true]},{"op":"withColumn","column":"computed","expr":"col('id')"}],"expected":{"schema":[{"name":"age","type":"bigint"},{"name":"department","type":"string"},{"name":"hire_date","type":"string"},{"name":"id","type":"bigint"},{"name":"name","type":"string"},{"name":"salary","type":"double"},{"name":"bonus","type":"double"}],"rows":[[40,"Finance","2018-11-05",4,"David",80000.0,8000.0],[35,"IT","2021-07-22",3,"Charlie",70000.0,7000.0],[30,"HR","2019-03-10",2,"Bob",60000.0,6000.0],[28,"IT","2022-02-14",5,"Eve",55000.0,5500.0]]},"skip":true,"skip_reason":"Expected shape from Sparkless converter; regenerate expected from PySpark for parity"}