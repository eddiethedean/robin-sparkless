[workspace]
members = []

[package]
name = "robin-sparkless"
version = "0.11.0"
edition = "2021"
description = "PySpark-like DataFrame API in Rust on Polars; no JVM."
readme = "README.md"
license = "MIT"
repository = "https://github.com/eddiethedean/robin-sparkless"
keywords = ["pyspark", "polars", "dataframe", "spark", "etl"]
categories = ["data-structures", "development-tools"]
authors = ["Robin Sparkless contributors"]

[lib]
name = "robin_sparkless"
# When building the Python wheel, maturin adds cdylib. We use abi3 for Py 3.8+ wheels.
crate-type = ["rlib"]

[features]
default = []
pyo3 = ["dep:pyo3", "dep:spark-ddl-parser"]
sql = ["dep:sqlparser"]
delta = ["dep:deltalake", "dep:tokio"]

[dependencies]
polars = { version = "0.45", features = ["lazy", "csv", "parquet", "json", "temporal", "strings", "concat_str", "regex", "round_series", "abs", "dtype-categorical", "dtype-date", "dtype-datetime", "dtype-duration", "dtype-time", "rank", "is_in", "list_eval", "list_drop_nulls", "list_any_all", "cum_agg", "string_pad", "string_reverse", "repeat_by", "log", "month_end", "describe", "cross_join", "semi_anti_join", "extract_jsonpath", "dtype-struct", "random", "product", "moment"] }
polars-plan = "0.45"
serde = { version = "1.0", features = ["derive"] }
chrono = "0.4"
chrono-tz = "0.9"
serde_json = "1.0"
anyhow = "1.0"
thiserror = "1.0"
pyo3 = { version = "0.24", optional = true, features = ["abi3-py38", "extension-module"] }
spark-ddl-parser = { version = "0.1", optional = true }
sqlparser = { version = "0.45", optional = true }
deltalake = { version = "0.30", optional = true }
tokio = { version = "1", optional = true, features = ["rt", "rt-multi-thread", "fs", "io-util"] }
url = "2"
# URL encode/decode
percent-encoding = "2"
# String UDFs and list helpers (used in map closures)
strsim = "0.11"
crc32fast = "1.4"
twox-hash = "1.6"
murmur3 = "0.5"
soundex = "0.2"
# Pin to address RUSTSEC-2026-0007 (integer overflow in BytesMut::reserve; transitive via polars/deltalake)
bytes = "1.11.1"
# colRegex (column name pattern matching)
regex = "1.11"
# regexp_extract with lookahead/lookbehind (PySpark parity)
fancy-regex = "0.13"
# base64, binary hashes, encode/decode
base64 = "0.22"
hex = "0.4"
sha1 = "0.10"
sha2 = "0.10"
md5 = "0.7"
# rand/randn with seed support
rand = "0.8"
rand_distr = "0.4"
# AES crypto (PySpark aes_encrypt/aes_decrypt)
aes-gcm = "0.10"

# Use git sources when crates.io/cache is broken (e.g. "no targets specified" in manifest,
# or missing example bin in published tarball).
[patch.crates-io]
aead = { git = "https://github.com/RustCrypto/traits", tag = "aead-v0.5.2" }
aes = { git = "https://github.com/RustCrypto/block-ciphers", tag = "aes-v0.8.4" }
alloc-no-stdlib = { git = "https://github.com/dropbox/rust-alloc-no-stdlib", branch = "master" }
alloc-stdlib = { path = "vendor/alloc-stdlib" }
anes = { path = "vendor/anes" }

[dev-dependencies]
chrono = "0.4"
polars = { version = "0.45", features = ["lazy", "csv", "parquet", "json", "temporal", "strings", "concat_str", "regex", "round_series", "abs", "dtype-categorical", "dtype-date", "dtype-datetime", "dtype-duration", "dtype-time", "test", "rank", "is_in", "list_eval", "list_drop_nulls", "list_any_all", "cum_agg", "string_pad", "string_reverse", "repeat_by", "log", "month_end", "describe", "cross_join", "semi_anti_join", "extract_jsonpath", "dtype-struct", "product", "moment"] }
tempfile = "3"
criterion = "0.5"

[[bench]]
name = "filter_select_groupby"
harness = false
