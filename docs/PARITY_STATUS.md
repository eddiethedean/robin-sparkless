# Parity Status (PySpark vs Robin Sparkless)

This doc is the **living parity matrix** for `robin-sparkless`.

- **Oracle**: PySpark (fixtures generated by `tests/gen_pyspark_cases.py`)
- **Harness**: `tests/parity.rs`
- **Fixtures**: `tests/fixtures/*.json`
- **Sparkless integration**: Robin-sparkless is designed to replace Sparkless's backend. Sparkless has 270+ expected_outputs; a fixture converter can convert those to robin-sparkless format. See [SPARKLESS_INTEGRATION_ANALYSIS.md](SPARKLESS_INTEGRATION_ANALYSIS.md) ¬ß4.

Status as of **February 2026**: **PASSING (29 fixtures)**.

## Legend

- **‚úÖ Covered**: Covered by one or more fixtures (listed)
- **üöß Not yet covered**: Supported/partially supported but missing fixture coverage
- **‚ùå Not implemented**: Not implemented in the Rust API yet
- **‚ö†Ô∏è Diverges**: Implemented but intentionally differs from PySpark (must be documented)

## Coverage Matrix (high level)

| Area | Capability | Status | Fixtures |
| --- | --- | --- | --- |
| Data creation | `SparkSession::create_dataframe` (simple rows) | ‚úÖ Covered | `filter_age_gt_30`, `groupby_count`, `groupby_with_nulls` (and most others) |
| IO | `read_csv` | ‚úÖ Covered | `read_csv` |
| IO | `read_parquet` | ‚úÖ Covered | `read_parquet` |
| IO | `read_json` | ‚úÖ Covered | `read_json` |
| DataFrame | `select` | ‚úÖ Covered | many (e.g. `filter_age_gt_30`) |
| DataFrame | `filter` basic comparisons | ‚úÖ Covered | `filter_age_gt_30` |
| DataFrame | `filter` nested boolean logic | ‚úÖ Covered | `filter_and_or`, `filter_nested`, `filter_not` |
| DataFrame | `orderBy` | ‚úÖ Covered | many (e.g. `filter_age_gt_30`, `groupby_count`) |
| GroupBy | `groupBy(...).count()` | ‚úÖ Covered | `groupby_count`, `groupby_with_nulls` |
| GroupBy | `groupBy(...).sum()` | ‚úÖ Covered | `groupby_sum` |
| GroupBy | `groupBy(...).avg()` | ‚úÖ Covered | `groupby_avg` |
| GroupBy | `groupBy(...).min()` | ‚úÖ Covered | `groupby_min` |
| GroupBy | `groupBy(...).max()` | ‚úÖ Covered | `groupby_max` |
| GroupBy | groupBy with NULL keys | ‚úÖ Covered | `groupby_null_keys` |
| GroupBy | multi-agg `agg([..])` | üöß Not yet covered | (test harness needs update) |
| DataFrame | `withColumn` (arithmetic) | ‚úÖ Covered | `type_coercion_mixed` |
| DataFrame | `withColumn` (logical/boolean) | ‚úÖ Covered | `with_logical_column` |
| DataFrame | `withColumn` (mixed arithmetic + comparison) | ‚úÖ Covered | `with_arithmetic_logical_mix` |
| Functions | `when().then().otherwise()` | ‚úÖ Covered | `when_otherwise`, `when_then_otherwise` |
| Functions | `coalesce()` | ‚úÖ Covered | `coalesce` |
| Null semantics | NULL equality/inequality | ‚úÖ Covered | `null_comparison_equality` |
| Null semantics | NULL ordering comparisons | ‚úÖ Covered | `null_comparison_ordering` |
| Null semantics | `eqNullSafe` | ‚úÖ Covered | `null_safe_equality` |
| Null semantics | NULLs inside filter predicates | ‚úÖ Covered | `null_in_filter` |
| Type coercion | numeric comparison coercion (int vs double) | ‚úÖ Covered | `type_coercion_numeric` |
| Type coercion | numeric arithmetic coercion (int + double) | ‚úÖ Covered | `type_coercion_mixed` |
| Joins | inner/left/right/outer joins | ‚úÖ Covered | `inner_join`, `left_join`, `right_join`, `outer_join` |
| Windows | window functions | ‚ùå Not implemented | ‚Äî |
| SQL | `SparkSession::sql()` | ‚ùå Not implemented | ‚Äî |

## Fixture Index

| Fixture | What it covers |
| --- | --- |
| `filter_age_gt_30` | Filter + select + orderBy (baseline) |
| `filter_and_or` | AND/OR precedence + parentheses |
| `filter_nested` | Nested boolean logic |
| `filter_not` | NOT / negation |
| `groupby_count` | groupBy + count + orderBy |
| `groupby_with_nulls` | groupBy with NULLs |
| `groupby_sum` | groupBy + sum |
| `groupby_avg` | groupBy + avg |
| `groupby_min` | groupBy + min |
| `groupby_max` | groupBy + max |
| `groupby_null_keys` | groupBy with NULL keys |
| `read_csv` | CSV read path + operations |
| `read_parquet` | Parquet read path + operations |
| `read_json` | JSON read path + operations |
| `with_logical_column` | Logical columns/expressions in withColumn |
| `with_arithmetic_logical_mix` | Mixed arithmetic + comparison in withColumn |
| `when_otherwise` | when/then/otherwise |
| `when_then_otherwise` | chained when |
| `coalesce` | coalesce null handling |
| `null_comparison_equality` | NULL equality/inequality semantics |
| `null_comparison_ordering` | NULL ordering semantics |
| `null_safe_equality` | eqNullSafe semantics |
| `null_in_filter` | NULLs in filter predicates |
| `type_coercion_numeric` | int/double comparison coercion |
| `type_coercion_mixed` | int+double arithmetic coercion |
| `inner_join` | inner join on dept_id |
| `left_join` | left join + orderBy |
| `right_join` | right join + orderBy |
| `outer_join` | outer join + orderBy |

## Next additions to the matrix (recommended)

- Update test harness to support **multiple aggregations** in one `agg` call, then add fixture.
- Add join edge-case fixtures (null keys, duplicate keys).
- Add string function fixtures (`concat`, `substring`, `lower`, `upper`, etc.).

## Sparkless Test Conversion

Sparkless ([github.com/eddiethedean/sparkless](https://github.com/eddiethedean/sparkless)) has 270+ JSON expected outputs in `tests/expected_outputs/`. These can drive robin-sparkless parity tests via a fixture converter that maps Sparkless JSON format ‚Üí robin-sparkless fixture format. See [SPARKLESS_INTEGRATION_ANALYSIS.md](SPARKLESS_INTEGRATION_ANALYSIS.md) ¬ß4 for:
- Fixture format comparison (input_data vs input/rows; expected_output vs expected)
- Conversion steps per test
- Priority order: parity/dataframe, parity/functions, then parity/sql

