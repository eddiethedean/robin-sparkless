# Parity Status (PySpark vs Robin Sparkless)

This doc is the **living parity matrix** for `robin-sparkless`.

- **Oracle**: PySpark (fixtures generated by `tests/gen_pyspark_cases.py`)
- **Harness**: `tests/parity.rs`
- **Fixtures**: `tests/fixtures/*.json`
- **Sparkless integration**: Robin-sparkless is designed to replace Sparkless's backend. Sparkless has 270+ expected_outputs; a fixture converter can convert those to robin-sparkless format. See [SPARKLESS_INTEGRATION_ANALYSIS.md](SPARKLESS_INTEGRATION_ANALYSIS.md) ¬ß4.

Status as of **February 2026**: **PASSING (51 fixtures)**. Python smoke tests for the PyO3 bridge live in `tests/python/` (run via `make test` or `make test-python`); see [PYTHON_API.md](PYTHON_API.md).

## Legend

- **‚úÖ Covered**: Covered by one or more fixtures (listed)
- **üöß Not yet covered**: Supported/partially supported but missing fixture coverage
- **‚ùå Not implemented**: Not implemented in the Rust API yet
- **‚ö†Ô∏è Diverges**: Implemented but intentionally differs from PySpark (must be documented)

## Coverage Matrix (high level)

| Area | Capability | Status | Fixtures |
| --- | --- | --- | --- |
| Data creation | `SparkSession::create_dataframe` (simple rows) | ‚úÖ Covered | `filter_age_gt_30`, `groupby_count`, `groupby_with_nulls` (and most others) |
| IO | `read_csv` | ‚úÖ Covered | `read_csv` |
| IO | `read_parquet` | ‚úÖ Covered | `read_parquet` |
| IO | `read_json` | ‚úÖ Covered | `read_json` |
| DataFrame | `select` | ‚úÖ Covered | many (e.g. `filter_age_gt_30`) |
| DataFrame | `filter` basic comparisons | ‚úÖ Covered | `filter_age_gt_30` |
| DataFrame | `filter` nested boolean logic | ‚úÖ Covered | `filter_and_or`, `filter_nested`, `filter_not` |
| DataFrame | `orderBy` | ‚úÖ Covered | many (e.g. `filter_age_gt_30`, `groupby_count`) |
| GroupBy | `groupBy(...).count()` | ‚úÖ Covered | `groupby_count`, `groupby_with_nulls` |
| GroupBy | `groupBy(...).sum()` | ‚úÖ Covered | `groupby_sum` |
| GroupBy | `groupBy(...).avg()` | ‚úÖ Covered | `groupby_avg` |
| GroupBy | `groupBy(...).min()` | ‚úÖ Covered | `groupby_min` |
| GroupBy | `groupBy(...).max()` | ‚úÖ Covered | `groupby_max` |
| GroupBy | groupBy with NULL keys | ‚úÖ Covered | `groupby_null_keys` |
| GroupBy | groupBy single-row groups / single group | ‚úÖ Covered | `groupby_single_row_groups`, `groupby_single_group` |
| GroupBy | multi-agg `agg([..])` | ‚úÖ Covered | `groupby_multi_agg` |
| GroupBy | stddev, variance, count_distinct in agg | ‚úÖ Covered | `groupby_stddev_count_distinct` |
| DataFrame | `withColumn` (arithmetic) | ‚úÖ Covered | `type_coercion_mixed` |
| DataFrame | `withColumn` (logical/boolean) | ‚úÖ Covered | `with_logical_column` |
| DataFrame | `withColumn` (mixed arithmetic + comparison) | ‚úÖ Covered | `with_arithmetic_logical_mix` |
| Functions | `when().then().otherwise()` | ‚úÖ Covered | `when_otherwise`, `when_then_otherwise` |
| Functions | `coalesce()` | ‚úÖ Covered | `coalesce` |
| Null semantics | NULL equality/inequality | ‚úÖ Covered | `null_comparison_equality` |
| Null semantics | NULL ordering comparisons | ‚úÖ Covered | `null_comparison_ordering` |
| Null semantics | `eqNullSafe` | ‚úÖ Covered | `null_safe_equality` |
| Null semantics | NULLs inside filter predicates | ‚úÖ Covered | `null_in_filter` |
| Type coercion | numeric comparison coercion (int vs double) | ‚úÖ Covered | `type_coercion_numeric` |
| Type coercion | numeric arithmetic coercion (int + double) | ‚úÖ Covered | `type_coercion_mixed` |
| Joins | inner/left/right/outer joins | ‚úÖ Covered | `inner_join`, `left_join`, `right_join`, `outer_join` |
| Joins | join with NULL keys (inner: nulls excluded) | ‚úÖ Covered | `join_null_keys` |
| Joins | join with duplicate keys (cartesian match) | ‚úÖ Covered | `join_duplicate_keys` |
| Windows | row_number, rank, dense_rank, lag, lead | ‚úÖ Covered | `row_number_window`, `rank_window`, `lag_lead_window` |
| Strings | upper, lower, substring, concat, concat_ws | ‚úÖ Covered | `string_upper_lower`, `string_substring`, `string_concat` |
| Strings | length, trim, ltrim, rtrim, regexp_extract, regexp_replace, split, initcap | ‚úÖ Covered | `string_length_trim` |
| Config | `spark.sql.caseSensitive` (case-insensitive column resolution) | ‚úÖ Covered | `case_insensitive_columns` |
| DataFrame | `union` / `unionAll` | ‚úÖ Covered | `union_all` |
| DataFrame | `unionByName` | ‚úÖ Covered | `union_by_name` |
| DataFrame | `distinct` / `dropDuplicates` | ‚úÖ Covered | `distinct` |
| DataFrame | `drop` (columns) | ‚úÖ Covered | `drop_columns` |
| DataFrame | `dropna` | ‚úÖ Covered | `dropna` |
| DataFrame | `fillna` (single value) | ‚úÖ Covered | `fillna` |
| DataFrame | `limit` | ‚úÖ Covered | `limit` |
| DataFrame | `withColumnRenamed` | ‚úÖ Covered | `with_column_renamed` |
| SQL | `SparkSession::sql()` | ‚ùå Not implemented | ‚Äî |

## Fixture Index

| Fixture | What it covers |
| --- | --- |
| `filter_age_gt_30` | Filter + select + orderBy (baseline) |
| `filter_and_or` | AND/OR precedence + parentheses |
| `filter_nested` | Nested boolean logic |
| `filter_not` | NOT / negation |
| `groupby_count` | groupBy + count + orderBy |
| `groupby_with_nulls` | groupBy with NULLs |
| `groupby_sum` | groupBy + sum |
| `groupby_avg` | groupBy + avg |
| `groupby_min` | groupBy + min |
| `groupby_max` | groupBy + max |
| `groupby_null_keys` | groupBy with NULL keys |
| `groupby_single_row_groups` | groupBy with single-row groups (each key once) |
| `groupby_single_group` | groupBy with single group (all same key) |
| `join_null_keys` | inner join with NULL join keys (nulls excluded) |
| `join_duplicate_keys` | inner join with duplicate keys (multiple matches) |
| `case_insensitive_columns` | case-insensitive column resolution (filter/select/orderBy with mixed-case names) |
| `read_csv` | CSV read path + operations |
| `read_parquet` | Parquet read path + operations |
| `read_json` | JSON read path + operations |
| `with_logical_column` | Logical columns/expressions in withColumn |
| `with_arithmetic_logical_mix` | Mixed arithmetic + comparison in withColumn |
| `when_otherwise` | when/then/otherwise |
| `when_then_otherwise` | chained when |
| `coalesce` | coalesce null handling |
| `null_comparison_equality` | NULL equality/inequality semantics |
| `null_comparison_ordering` | NULL ordering semantics |
| `null_safe_equality` | eqNullSafe semantics |
| `null_in_filter` | NULLs in filter predicates |
| `type_coercion_numeric` | int/double comparison coercion |
| `type_coercion_mixed` | int+double arithmetic coercion |
| `inner_join` | inner join on dept_id |
| `left_join` | left join + orderBy |
| `right_join` | right join + orderBy |
| `outer_join` | outer join + orderBy |
| `groupby_multi_agg` | groupBy + multiple aggregations in one agg() |
| `groupby_stddev_count_distinct` | groupBy + stddev and count_distinct in agg |
| `row_number_window` | row_number() over partition by dept order by salary desc |
| `rank_window` | rank() over partition with ties |
| `lag_lead_window` | lag and lead over partition |
| `string_upper_lower` | upper(), lower() |
| `string_substring` | substring() 1-based |
| `string_concat` | concat(), concat_ws() |
| `string_length_trim` | length(), trim() in withColumn |
| `union_all` | union (vertical stack, same schema) |
| `union_by_name` | unionByName (align columns by name) |
| `distinct` | distinct (drop duplicate rows) |
| `drop_columns` | drop(columns) |
| `dropna` | dropna (drop rows with nulls) |
| `fillna` | fillna (fill nulls with value) |
| `limit` | limit(n) |
| `with_column_renamed` | withColumnRenamed(old, new) |

## Next additions to the matrix (recommended)

- Add more join edge-case fixtures (e.g. left/outer with null keys) if needed.

## Sparkless Test Conversion

Sparkless ([github.com/eddiethedean/sparkless](https://github.com/eddiethedean/sparkless)) has 270+ JSON expected outputs in `tests/expected_outputs/`. These can drive robin-sparkless parity tests via a fixture converter that maps Sparkless JSON format ‚Üí robin-sparkless fixture format. See [SPARKLESS_INTEGRATION_ANALYSIS.md](SPARKLESS_INTEGRATION_ANALYSIS.md) ¬ß4 for:
- Fixture format comparison (input_data vs input/rows; expected_output vs expected)
- Conversion steps per test
- Priority order: parity/dataframe, parity/functions, then parity/sql

